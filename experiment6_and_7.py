'''
experiment6_and_7.py
This script tests the overlay of segmentation masks generated by combining GradCAM-based visualizations with SAM predictions. It computes evaluation metrics—including IoU and ROAD metrics—by comparing generated masks against ground truth masks, and saves detailed results for further analysis.

Usage:
- Ensure that the input image and ground truth mask directories are correctly set in `IMAGES_PATH` and `MASK_PATH`.
- Verify that the necessary checkpoints for the mobile SAM predictor, SAM model, and image classifier are available.
- Adjust parameters such as `image_size`, `class_target`, `cam_method`, `eigen_smooth`, `aug_smooth`, and `threshold` as needed.
- Run the script to generate overlays, compute evaluation metrics, and save the results into CSV files within the experiment folder.

Steps:
1. Create experiment and GradCAM output directories.
2. Load and resize images along with their corresponding ground truth masks.
3. Retrieve precomputed GradCAM maps using stored paths.
4. Generate segmentation masks from GradCAM maps via bounding box extraction and SAM predictions.
5. Load SAM masks and prune them based on area and quality thresholds.
6. Compute the best overlap (IoU) between SAM masks and GradCAM-derived masks.
7. Calculate ROAD metrics (Combined and Most Relevant First) for both original and visualization-based CAMs.
8. Combine the masks (logical OR) and compute final evaluation metrics.
9. Save per-image metrics and aggregated statistics to CSV files in the experiment folder.

Outputs:
- CSV files with evaluation metrics: `overlay_metrics.csv`, `vis_overlay_metrics.csv`, `vis_metrics.csv`, and `combined_metrics.csv`.
- Corresponding statistics CSV files: `overlay_statistics.csv`, `vis_overlay_statistics.csv`, `vis_statistics.csv`, and `combined_statistics.csv`.

Dependencies:
- Standard libraries: os, time, pathlib
- External libraries: cv2, PIL, pandas, torch, numpy, matplotlib, torchvision, pytorch_grad_cam, tqdm
- Custom modules: models (load_mobile_segment_anything_predictor, load_segment_anything, load_image_classifier) and utils (find_bounding_box, get_stored_gradcam, calculate_all_metrics, find_grad_cam_path, calculate_statistics, prune_masks_if_blackish, prune_masks_outside_area, create_experiment_folder, find_overlap_with_iou)
'''

import os
import time
from pathlib import Path

import cv2

from PIL import Image

import pandas as pd
import torch
from pytorch_grad_cam.utils.image import show_cam_on_image

from torchvision import transforms

import numpy as np
from pytorch_grad_cam import FullGrad, LayerCAM, XGradCAM, ScoreCAM, AblationCAM, EigenGradCAM, EigenCAM, HiResCAM, \
    GradCAMElementWise, GradCAMPlusPlus, GradCAM
from pytorch_grad_cam.metrics.road import ROADCombined, ROADMostRelevantFirst
from pytorch_grad_cam.utils.model_targets import ClassifierOutputSoftmaxTarget, ClassifierOutputTarget
from tqdm import tqdm

from models import load_mobile_segment_anything_predictor, load_segment_anything, load_image_classifier
from utils import find_bounding_box, get_stored_gradcam, calculate_all_metrics, \
    find_grad_cam_path, calculate_statistics, prune_masks_if_blackish, prune_masks_outside_area, \
    create_experiment_folder, find_overlap_with_iou

image_size = (224, 224)
class_target = 5

IMAGES_PATH = Path('/mnt/e/Datasets/kvasir-seg/Kvasir-SEG/images')
MASK_PATH = Path('/mnt/e/Datasets/kvasir-seg/Kvasir-SEG/masks')

experiments_dir = Path('/mnt/e/SAMexperiments/experiments')
generated_gradcam_dir = Path('/mnt/e/SAMexperiments/generated_gradcams')

experiments_dir.mkdir(exist_ok=True)
generated_gradcam_dir.mkdir(exist_ok=True)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
predictor = load_mobile_segment_anything_predictor('vit_t', 'checkpoints/mobile_sam.pt', device=device)

cam_methods = {
        'GradCAM': GradCAM,
        'GradCAM++': GradCAMPlusPlus,
        'GradCAMElementWise': GradCAMElementWise,
        'HiResCAM': HiResCAM,
        'EigenCAM': EigenCAM,
        'EigenGradCAM': EigenGradCAM,
        'AblationCAM': AblationCAM,
        'ScoreCAM': ScoreCAM,
        'XGradCAM': XGradCAM,
        'LayerCAM': LayerCAM,
        'FullGrad': FullGrad
    }


image_classifier_model_path = Path('checkpoints', 'model_epochs47_batch32.pth')
image_classifier = load_image_classifier(image_classifier_model_path)


def generate_cam(cam, original_image, image_tensor, class_targets, eigen=False, aug=False):
    grayscale_cam = cam(
        input_tensor=image_tensor,
        targets=class_targets,
        eigen_smooth=eigen,
        aug_smooth=aug
    )
    grayscale_cam = grayscale_cam[0, :]
    output_on_image = show_cam_on_image(
        cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR),
        grayscale_cam,
        use_rgb=True
    )
    return grayscale_cam, output_on_image


def run_overlay_test():
    experiment_folder = create_experiment_folder(experiments_dir, 'overlay_test')

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    images_path = IMAGES_PATH
    gt_mask_path = MASK_PATH

    image_name_list = os.listdir(images_path)

    cam_method = 'ScoreCAM'
    eigen_smooth = False
    aug_smooth = True
    threshold = 0.6156759427375402

    cam_descriptor = f'{cam_method}_eigen={eigen_smooth}_aug={aug_smooth}'
    cam_experiment_folder = Path(experiment_folder, cam_descriptor)
    cam_experiment_folder.mkdir(exist_ok=True)

    # Load all saved gradcams
    print('Loading CAMs')
    first_image = image_name_list[0]
    grad_cam_base = find_grad_cam_path(str(images_path / first_image), str(images_path.parent.name), generated_gradcam_dir).parent / cam_descriptor

    metrics = {}
    metrics_vis = {}
    metrics_no_overlap = {}
    metrics_combined = {}
    for image_index, image_name in tqdm(enumerate(image_name_list), total=len(image_name_list)):
        start_time = time.time()
        image = Image.open(images_path / image_name)
        image = image.resize(image_size)
        image_np = np.array(image)
        truth_mask = Image.open(gt_mask_path / image_name)
        truth_mask = truth_mask.resize(image_size)
        truth_mask = truth_mask.convert('L')
        truth_mask = np.array(truth_mask) > 0.5
        grayscale_cam = get_stored_gradcam(grad_cam_base, Path(image_name_list[image_index]))

        print('Generating masks from CAMs')
        bounding_box = find_bounding_box(grayscale_cam, threshold)
        predictor.set_image(image_np)
        mask_bounding_box, _, _ = predictor.predict(
            point_coords=None,
            point_labels=None,
            box=bounding_box,
            multimask_output=False,
        )

        mask_generator = load_segment_anything('vit_h', 'checkpoints/sam_vit_h_4b8939.pth', device=device)
        sam_masks = mask_generator.generate(image_np)

        print('Finished loading CAM and images')
        # Prune masks
        sam_masks = prune_masks_outside_area(image_np.shape[0] * image_np.shape[1], sam_masks)
        sam_masks = prune_masks_if_blackish(sam_masks, image_np, threshold=30, blackish_threshold=0.5)

        best_mask, best_iou = find_overlap_with_iou(sam_masks, mask_bounding_box[0])
        if best_iou > 0.1:
            best_mask = best_mask['segmentation']
            used_overlay = 1
        else:
            best_mask = mask_bounding_box[0]
            best_iou = 0.0
            used_overlay = 0

        metrics[image_name] = calculate_all_metrics(truth_mask.ravel(), best_mask.ravel())
        metrics[image_name]['time'] = time.time() - start_time
        metrics[image_name]['best_overlap_iou'] = best_iou
        metrics[image_name]['used_overlay'] = used_overlay

        # Calculate ROAD Combined
        cam_metric = ROADCombined(percentiles=[20, 40, 60, 80])
        metric_targets = [ClassifierOutputSoftmaxTarget(5)]
        normalize = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.4762, 0.3054, 0.2368],
                                 [0.3345, 0.2407, 0.2164])
        ])
        input_tensor = normalize(image_np).unsqueeze(0).to(device)
        scores = cam_metric(input_tensor, np.array([grayscale_cam]), metric_targets, image_classifier)
        metrics[image_name]['ROAD Combined'] = scores[0]

        start_time = time.time()
        cam_metric = ROADMostRelevantFirst(percentile=80)
        scores, visualizations = cam_metric(input_tensor, np.expand_dims(grayscale_cam, axis=0), metric_targets,
                                            image_classifier, return_visualization=True)

        visualization = visualizations[0].cpu().numpy().transpose((1, 2, 0))
        visualization = np.clip(visualization, 0, 1)

        input_tensor = normalize(visualization).unsqueeze(0).to(device)

        # Generate class activation map
        with cam_methods[cam_method](model=image_classifier, target_layers=[image_classifier.features[-1]]) as cam:
            grayscale_cam, heatmap = generate_cam(cam, visualization, input_tensor,
                                                  [ClassifierOutputTarget(class_target)], eigen_smooth, aug_smooth)

        print('Generating masks from visualization CAMs')
        bounding_box = find_bounding_box(grayscale_cam, threshold)
        predictor.set_image(visualization)
        mask_bounding_box, _, _ = predictor.predict(
            point_coords=None,
            point_labels=None,
            box=bounding_box,
            multimask_output=False,
        )

        metrics_no_overlap[image_name] = calculate_all_metrics(truth_mask.ravel(), mask_bounding_box[0].ravel())
        metrics_no_overlap[image_name]['time'] = time.time() - start_time

        best_vis_mask, best_iou = find_overlap_with_iou(sam_masks, mask_bounding_box[0])

        if best_iou > 0.1:
            best_vis_mask = best_vis_mask['segmentation']
            used_overlay = 1
        else:
            best_vis_mask = mask_bounding_box[0]
            best_iou = 0.0
            used_overlay = 0

        metrics_vis[image_name] = calculate_all_metrics(truth_mask.ravel(), best_vis_mask.ravel())
        metrics_vis[image_name]['time'] = time.time() - start_time
        metrics_vis[image_name]['best_overlap_iou'] = best_iou
        metrics_vis[image_name]['used_overlay'] = used_overlay

        # Calculate ROAD Combined
        cam_metric = ROADCombined(percentiles=[20, 40, 60, 80])
        metric_targets = [ClassifierOutputSoftmaxTarget(5)]
        transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.4762, 0.3054, 0.2368],
                                 [0.3345, 0.2407, 0.2164])
        ])
        input_tensor = transforms.ToTensor()(image_np).unsqueeze(0).to(device)
        scores = cam_metric(input_tensor, np.array([grayscale_cam]), metric_targets, image_classifier)
        metrics_vis[image_name]['ROAD Combined'] = scores[0]

        # Combine the masks
        best_mask = best_mask | best_vis_mask
        metrics_combined[image_name] = calculate_all_metrics(truth_mask.ravel(), best_mask.ravel())

    statistics = calculate_statistics(metrics)

    pd.DataFrame(metrics).to_csv(cam_experiment_folder / 'overlay_metrics.csv')
    statistics.to_csv(cam_experiment_folder / 'overlay_statistics.csv')

    statistics = calculate_statistics(metrics_vis)

    pd.DataFrame(metrics_vis).to_csv(cam_experiment_folder / 'vis_overlay_metrics.csv')
    statistics.to_csv(cam_experiment_folder / 'vis_overlay_statistics.csv')

    statistics = calculate_statistics(metrics_no_overlap)

    pd.DataFrame(metrics_no_overlap).to_csv(cam_experiment_folder / 'vis_metrics.csv')
    statistics.to_csv(cam_experiment_folder / 'vis_statistics.csv')

    statistics = calculate_statistics(metrics_combined)

    pd.DataFrame(metrics_combined).to_csv(cam_experiment_folder / 'combined_metrics.csv')
    statistics.to_csv(cam_experiment_folder / 'combined_statistics.csv')


if __name__ == '__main__':
    run_overlay_test()